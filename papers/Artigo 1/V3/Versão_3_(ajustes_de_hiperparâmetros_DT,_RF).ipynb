{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aureavaleria/DataBalancing-Research/blob/main/papers/Artigo%201/V3/Vers%C3%A3o_3_(ajustes_de_hiperpar%C3%A2metros_DT%2C_RF).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuLJn5A4B7XA"
      },
      "source": [
        "### ***Machine learning for predicting liver and/or lung metastasis in colorectal cancer: A retrospective study based on the SEER database***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6nNMd_ZF8r7"
      },
      "source": [
        "Este notebook apresenta um processo de otimização de hiperparâmetros para o modelo Decision tree e Random Forest, utilizando dados extraídos da base SEER, amplamente utilizada em pesquisas oncológicas. O objetivo é ajustar os parâmetros do modelo de forma iterativa, maximizando sua performance com base na métrica AUC-ROC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsC61a-EHKfA"
      },
      "source": [
        "### Parte 1:  Importação das Bibliotecas e Carregamento do Dataset\n",
        "\n",
        "Nesta etapa, importamos as bibliotecas necessárias para análise e carregamos o dataset. Realizamos uma verificação inicial para identificar e remover valores faltantes e definimos as variáveis preditoras (X) e as variáveis alvo (y), preparando os dados para o pré-processamento e a modelagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6zj66AQc_z9U",
        "outputId": "513c7091-913a-4634-82c7-3759bab793d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores faltantes por coluna:\n",
            " Patient ID                                         0\n",
            "Age recode with <1 year olds                       0\n",
            "Sex                                                0\n",
            "Race recode (White, Black, Other)                  0\n",
            "Histologic Type ICD-O-3                            0\n",
            "Grade Recode (thru 2017)                           0\n",
            "Primary Site                                       0\n",
            "Derived AJCC T, 7th ed (2010-2015)                 0\n",
            "Derived AJCC N, 7th ed (2010-2015)                 0\n",
            "CS tumor size (2004-2015)                          0\n",
            "CEA Pretreatment Interpretation Recode (2010+)     0\n",
            "Tumor Deposits Recode (2010+)                      0\n",
            "Marital status at diagnosis                        0\n",
            "Origin recode NHIA (Hispanic, Non-Hisp)            0\n",
            "SEER Combined Mets at DX-lung (2010+)             15\n",
            "SEER Combined Mets at DX-liver (2010+)            12\n",
            "SEER Combined Mets at DX-bone (2010+)             14\n",
            "ICD-O-3 Hist/behav                                 0\n",
            "ICD-O-3 Hist/behav, malignant                      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Importação das bibliotecas essenciais para análise de dados, visualização e aprendizado de máquina\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Importação de funções e classes específicas para pré-processamento, modelagem e avaliação\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import (roc_curve, roc_auc_score, confusion_matrix,\n",
        "                             classification_report, precision_recall_curve, average_precision_score)\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Carregar o dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/aureavaleria/Reprodu-o/main/export.csv')\n",
        "\n",
        "# Verificar se existem valores faltantes (NaN) e exibir quantos valores faltantes existem por coluna\n",
        "print(\"Valores faltantes por coluna:\\n\", df.isnull().sum())\n",
        "\n",
        "# Remover as linhas com valores faltantes\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Definir as variáveis preditoras (X)\n",
        "X = df[['Age recode with <1 year olds', 'Sex', 'Race recode (White, Black, Other)',\n",
        "        'Histologic Type ICD-O-3', 'Grade Recode (thru 2017)', 'Primary Site',\n",
        "        'Derived AJCC T, 7th ed (2010-2015)', 'Derived AJCC N, 7th ed (2010-2015)',\n",
        "        'CS tumor size (2004-2015)', 'CEA Pretreatment Interpretation Recode (2010+)',\n",
        "        'Tumor Deposits Recode (2010+)', 'Marital status at diagnosis',\n",
        "        'Origin recode NHIA (Hispanic, Non-Hisp)']]\n",
        "\n",
        "# Definir as variáveis alvo: Metástase no fígado e no pulmão\n",
        "y_liver = df['SEER Combined Mets at DX-liver (2010+)']\n",
        "y_lung = df['SEER Combined Mets at DX-lung (2010+)']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv7ZXmnvLghh"
      },
      "source": [
        "###Parte 2:  Preparação das Variáveis Alvo e Codificação de Variáveis Categóricas\n",
        "\n",
        "Nesta etapa, preparamos as variáveis alvo (y), combinando as informações de metástase hepática e pulmonar em uma coluna binária para indicar a presença de metástase. Também aplicamos LabelEncoder para transformar variáveis categóricas de X em valores numéricos, facilitando o uso dos dados em modelos de aprendizado de máquina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slmbLH5kLdKP",
        "outputId": "d9086551-71ca-4a76-a414-b74e55374051"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-2-1cd8977feba9>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamanho de X: 53448\n",
            "Tamanho de y: 53448\n"
          ]
        }
      ],
      "source": [
        "# Concatenar as variáveis alvo 'y_liver' e 'y_lung' em um DataFrame 'y' para problemas multi-label\n",
        "y = pd.concat([y_liver, y_lung], axis=1)\n",
        "\n",
        "# Aplicar codificação a variáveis categóricas em 'X' usando LabelEncoder, para prepará-las para o modelo\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':  # Verifica se a coluna é categórica (strings)\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Função para combinar as informações de metástase hepática e pulmonar em uma coluna binária 'Binary Mets'\n",
        "# (0 = sem metástase, 1 = com metástase)\n",
        "def combine_mets_binary(row):\n",
        "    if row['SEER Combined Mets at DX-liver (2010+)'] == 'Yes' or row['SEER Combined Mets at DX-lung (2010+)'] == 'Yes':\n",
        "        return 1  # Com metástase\n",
        "    else:\n",
        "        return 0  # Sem metástase\n",
        "\n",
        "# Aplicar a função para criar a nova coluna binária 'Binary Mets' em 'y'\n",
        "y['Binary Mets'] = y.apply(combine_mets_binary, axis=1)\n",
        "\n",
        "# Verificar se 'X' e 'y' têm o mesmo número de amostras\n",
        "print(f\"Tamanho de X: {len(X)}\")\n",
        "print(f\"Tamanho de y: {len(y)}\")\n",
        "\n",
        "# Salvar o DataFrame 'y' em um arquivo CSV para referência futura ou análise adicional\n",
        "y.to_csv('/content/Y.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfbK68vJNOEX"
      },
      "source": [
        "###3. Otimização de hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zncc2wo0-3bq",
        "outputId": "f70226ef-106c-44ae-b700-6262ffc65ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Buscando os melhores parâmetros para: Decision Tree\n",
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Melhores parâmetros para Decision Tree: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
            "Melhor pontuação (AUC-ROC): 0.8590\n",
            "\n",
            "Buscando os melhores parâmetros para: Random Forest\n",
            "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores parâmetros para Random Forest: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "Melhor pontuação (AUC-ROC): 0.8839\n",
            "Resultados salvos no arquivo 'melhores_hiperparametros.txt'.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Modelos ajustados\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Dicionário com hiperparâmetros ajustados\n",
        "param_grids = {\n",
        "    \"Decision Tree\": {\n",
        "        \"max_depth\": [5, 10, 15, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 5, 10],\n",
        "        \"criterion\": [\"gini\", \"entropy\"]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"n_estimators\": [100, 200, 300],\n",
        "        \"max_depth\": [10, 15, 20, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 5, 10],\n",
        "        \"bootstrap\": [True, False],\n",
        "        \"criterion\": [\"gini\", \"entropy\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Preparar os resultados\n",
        "best_params = []\n",
        "\n",
        "# Rodar GridSearchCV para cada modelo\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nBuscando os melhores parâmetros para: {model_name}\")\n",
        "\n",
        "    # Definir os hiperparâmetros para o modelo atual\n",
        "    param_grid = param_grids[model_name]\n",
        "\n",
        "    # Configurar validação cruzada estratificada\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Instanciar o GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"roc_auc\",  # Métrica de avaliação\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Ajustar o GridSearch\n",
        "    grid_search.fit(X, y['Binary Mets'])\n",
        "\n",
        "    # Salvar os melhores parâmetros e a melhor pontuação\n",
        "    best_params.append({\n",
        "        \"Modelo\": model_name,\n",
        "        \"Melhores Parâmetros\": grid_search.best_params_,\n",
        "        \"Melhor Pontuação (AUC-ROC)\": grid_search.best_score_\n",
        "    })\n",
        "\n",
        "    print(f\"Melhores parâmetros para {model_name}: {grid_search.best_params_}\")\n",
        "    print(f\"Melhor pontuação (AUC-ROC): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Salvar os resultados em um arquivo TXT\n",
        "with open(\"melhores_hiperparametros.txt\", \"w\") as file:\n",
        "    file.write(\"Resultados da Busca de Hiperparâmetros (GridSearchCV):\\n\\n\")\n",
        "    for result in best_params:\n",
        "        file.write(f\"Modelo: {result['Modelo']}\\n\")\n",
        "        file.write(f\"  Melhores Parâmetros:\\n\")\n",
        "        for param, value in result['Melhores Parâmetros'].items():\n",
        "            file.write(f\"    {param}: {value}\\n\")\n",
        "        file.write(f\"  Melhor Pontuação (AUC-ROC): {result['Melhor Pontuação (AUC-ROC)']:.4f}\\n\")\n",
        "        file.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Resultados salvos no arquivo 'melhores_hiperparametros.txt'.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHpXSPT9fMmsteaDM+ZSdH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}