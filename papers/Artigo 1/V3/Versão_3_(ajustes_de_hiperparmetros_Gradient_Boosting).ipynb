{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf7hj0gTjP6e3K4l5wkNxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aureavaleria/DataBalancing-Research/blob/main/papers/Artigo%201/V3/Vers%C3%A3o_3_(ajustes_de_hiperparmetros_Gradient_Boosting).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Machine learning for predicting liver and/or lung metastasis in colorectal cancer: A retrospective study based on the SEER database***"
      ],
      "metadata": {
        "id": "RWJyqsg1vZ7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook apresenta um processo de otimização de hiperparâmetros para o modelo Gradient Boosting, utilizando dados extraídos da base SEER, amplamente utilizada em pesquisas oncológicas. O objetivo é ajustar os parâmetros do modelo de forma iterativa, maximizando sua performance com base na métrica AUC-ROC."
      ],
      "metadata": {
        "id": "s-wDDSpQvcs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Configuração inicial e importação das bibliotecas"
      ],
      "metadata": {
        "id": "684lwci7wt6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas essenciais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "BX3mNWDrvmPh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Carregamento e tratamento de dados"
      ],
      "metadata": {
        "id": "M7GmSze6w69D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/aureavaleria/Reprodu-o/main/export.csv')\n",
        "\n",
        "# Verificar e remover valores faltantes\n",
        "print(\"Valores faltantes por coluna:\\n\", df.isnull().sum())\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbryh8oyvqgV",
        "outputId": "40fdf735-e5d9-49cf-9da7-58e7c61c21cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores faltantes por coluna:\n",
            " Patient ID                                         0\n",
            "Age recode with <1 year olds                       0\n",
            "Sex                                                0\n",
            "Race recode (White, Black, Other)                  0\n",
            "Histologic Type ICD-O-3                            0\n",
            "Grade Recode (thru 2017)                           0\n",
            "Primary Site                                       0\n",
            "Derived AJCC T, 7th ed (2010-2015)                 0\n",
            "Derived AJCC N, 7th ed (2010-2015)                 0\n",
            "CS tumor size (2004-2015)                          0\n",
            "CEA Pretreatment Interpretation Recode (2010+)     0\n",
            "Tumor Deposits Recode (2010+)                      0\n",
            "Marital status at diagnosis                        0\n",
            "Origin recode NHIA (Hispanic, Non-Hisp)            0\n",
            "SEER Combined Mets at DX-lung (2010+)             15\n",
            "SEER Combined Mets at DX-liver (2010+)            12\n",
            "SEER Combined Mets at DX-bone (2010+)             14\n",
            "ICD-O-3 Hist/behav                                 0\n",
            "ICD-O-3 Hist/behav, malignant                      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Divisão de variáveis preditoras (X) e alvo (y)"
      ],
      "metadata": {
        "id": "Hcr8p1mcxDcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as variáveis preditoras (X)\n",
        "X = df[['Age recode with <1 year olds', 'Sex', 'Race recode (White, Black, Other)',\n",
        "        'Histologic Type ICD-O-3', 'Grade Recode (thru 2017)', 'Primary Site',\n",
        "        'Derived AJCC T, 7th ed (2010-2015)', 'Derived AJCC N, 7th ed (2010-2015)',\n",
        "        'CS tumor size (2004-2015)', 'CEA Pretreatment Interpretation Recode (2010+)',\n",
        "        'Tumor Deposits Recode (2010+)', 'Marital status at diagnosis',\n",
        "        'Origin recode NHIA (Hispanic, Non-Hisp)']]\n",
        "\n",
        "# Definir as variáveis alvo (y)\n",
        "y = df[['SEER Combined Mets at DX-liver (2010+)', 'SEER Combined Mets at DX-lung (2010+)']]"
      ],
      "metadata": {
        "id": "QxjUKn2IwDfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Codificação das variáveis categóricas"
      ],
      "metadata": {
        "id": "RmbLQDawxKNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar LabelEncoder às colunas categóricas em X\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object':  # Verifica se a coluna é categórica (strings)\n",
        "        X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Criar coluna binária 'Binary Mets'\n",
        "y['Binary Mets'] = np.where((y['SEER Combined Mets at DX-liver (2010+)'] == 'Yes') |\n",
        "                            (y['SEER Combined Mets at DX-lung (2010+)'] == 'Yes'), 1, 0)\n",
        "\n",
        "# Verificar os tamanhos de X e y\n",
        "print(f\"Tamanho de X: {len(X)}\")\n",
        "print(f\"Tamanho de y: {len(y)}\")\n",
        "\n",
        "# Renomear colunas de X para remover caracteres inválidos\n",
        "X.columns = [str(col).replace('[', '').replace(']', '').replace('<', '').replace('>', '').replace(' ', '_')\n",
        "             for col in X.columns]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHx50DrZwIiS",
        "outputId": "9e8bd13c-e802-4d7d-ce78-028eaaa2eca8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de X: 53448\n",
            "Tamanho de y: 53448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = LabelEncoder().fit_transform(X[col])\n",
            "<ipython-input-4-47dc951dc1ef>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y['Binary Mets'] = np.where((y['SEER Combined Mets at DX-liver (2010+)'] == 'Yes') |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Otimização de hiperparâmetros"
      ],
      "metadata": {
        "id": "40xs4eu5xRSQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYidXArVAI3",
        "outputId": "2ce2bbc5-94a1-4128-9cd5-cd5b94af9dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Otimização do grupo 1/3:\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Melhores parâmetros no grupo 1: {'max_depth': 3, 'n_estimators': 200}\n",
            "Pontuação no grupo 1 (AUC-ROC): 0.8855\n",
            "\n",
            "Otimização do grupo 2/3:\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Melhores parâmetros no grupo 2: {'learning_rate': 0.1, 'subsample': 0.8}\n",
            "Pontuação no grupo 2 (AUC-ROC): 0.8858\n",
            "\n",
            "Otimização do grupo 3/3:\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Melhores parâmetros no grupo 3: {'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "Pontuação no grupo 3 (AUC-ROC): 0.8858\n",
            "\n",
            "Parâmetros finais otimizados: {'max_depth': 3, 'n_estimators': 200, 'learning_rate': 0.1, 'subsample': 0.8, 'min_samples_leaf': 5, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "# Função para otimizar hiperparâmetros em grupos\n",
        "def optimize_hyperparameters(X, y, param_group, fixed_params=None):\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    model = GradientBoostingClassifier(random_state=42, **(fixed_params or {}))\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_group, scoring=\"roc_auc\", cv=cv, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search.best_params_, grid_search.best_score_\n",
        "\n",
        "# Hiperparâmetros divididos em grupos\n",
        "param_groups = [\n",
        "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 6]},\n",
        "    {\"learning_rate\": [0.01, 0.1], \"subsample\": [0.8, 1.0]},\n",
        "    {\"min_samples_split\": [2, 5], \"min_samples_leaf\": [1, 5]}\n",
        "]\n",
        "\n",
        "# Variáveis fixadas (começa vazio e é atualizado a cada etapa)\n",
        "fixed_params = {}\n",
        "\n",
        "# Iterar pelos grupos de hiperparâmetros\n",
        "for i, param_group in enumerate(param_groups):\n",
        "    print(f\"\\nOtimização do grupo {i + 1}/{len(param_groups)}:\")\n",
        "    best_params, best_score = optimize_hyperparameters(X, y['Binary Mets'], param_group, fixed_params)\n",
        "    fixed_params.update(best_params)\n",
        "    print(f\"Melhores parâmetros no grupo {i + 1}: {best_params}\")\n",
        "    print(f\"Pontuação no grupo {i + 1} (AUC-ROC): {best_score:.4f}\")\n",
        "\n",
        "# Parâmetros finais otimizados\n",
        "print(\"\\nParâmetros finais otimizados:\", fixed_params)\n",
        "\n",
        "# Salvar resultados em arquivo\n",
        "with open(\"melhores_hiperparametros_gb_dividido.txt\", \"w\") as file:\n",
        "    file.write(\"Modelo: Gradient Boosting (Otimização em Grupos)\\n\")\n",
        "    file.write(\"Parâmetros Finais:\\n\")\n",
        "    for param, value in fixed_params.items():\n",
        "        file.write(f\"  {param}: {value}\\n\")\n"
      ]
    }
  ]
}